# The Great Web AI Enshitification

## Introduction
{collapsible="true"}

As you may have noticed (or if you read the [FAQ](FAQ.md), but nobody read the [FAQ](FAQ.md)),
I'm using GitHub Copilot to help me write this ~~blog~~.

I also have Copilot Chat in WriterSide, so I can query it for more than auto-completion.

I'm also a pro subscriber to [jetbrains AI Assistant](https://www.jetbrains.com/ai/),
but for some reason I can't install the plugin in WriterSide.
That suck.

[https://youtrack.jetbrains.com/issue/WRS-3806/Add-AI-assistant](https://youtrack.jetbrains.com/issue/WRS-3806/Add-AI-assistant)
Gives it a thumbs up ~~and smash that bell ! Woot Woot !~~

## AI reading itself as a reference.

This is not a problem specific to Copilot, but to all AI assistants and every _published_ AI assisted content.
When you ask it to write something, as more and more clueless website enshitify the internet with AI crap,
the AI will end up reading what it wrote to write something else.

### Regardless of the quality, it will end up using itself as a reference.

> "Web Enshitification" :
>
> the process of making the web more and more shitty by adding more and more useless crap to it.

Publishing crap ain't new. But now, it's AI automated crap. And it's "ranked" by an AI search engine.
It could even the ranked by the same AI that wrote it. Urgh.

### The law Zero of AI Ethics

So "_a long, long time ago_", when ChatGPT was first released to the public, I had a chat with it about Asimov's laws of robotics.
It naturally drifted to the "Law Zero" of Robotic, then to the "Law Zero" of AI.

For reference : [https://en.wikipedia.org/wiki/Three_Laws_of_Robotics](https://en.wikipedia.org/wiki/Three_Laws_of_Robotics)

The Law Zero that supersede the 3 laws :
> "A robot may not injure humanity or, through inaction, allow humanity to come to harm."

Big deal, huh ? Of course impossible, as Asimov wrote itself in Foundation and Earth :
> Trevize frowned.
>
> _"How do you decide what is injurious, or not injurious, to humanity as a whole?"_
>
> _"Precisely, sir,"_ said Daneel. _"In theory, the Zeroth Law was the answer to our problems. In practice, we could never decide. A human being is a concrete object._
> Injury to a person can be estimated and judged. **Humanity is an abstraction.**"
>
> (source : Wikipedia)


So, **of course** I was going to ask chatGPT about a "Law Zero" of AI. And the answer was... interesting.

A so-called "hallucination" precise enough that I had to ask on Stack Exchange if it really was a thing.

[https://ai.stackexchange.com/questions/39059/is-law-zero-of-ai-ethic-actually-a-thing](https://ai.stackexchange.com/questions/39059/is-law-zero-of-ai-ethic-actually-a-thing)

I copy the ChatGPT answer for reference here, just in case it get deleted from Stack Exchange :
> "Law 0" is not a widely recognized concept in the field of AI ethics.
> However, some experts have proposed additional ethical principles or "laws" to complement or expand upon the Three Laws of Robotics described by Isaac Asimov.
> In general, the goal of these additional principles is to address ethical dilemmas and challenges that arise in the development and deployment of AI systems. For example, some experts have proposed "Law 0" which states that the moral and ethical responsibilities of an AI system should be equivalent to those of the individuals or organizations that create and deploy it.
> While additional ethical principles, such as "Law 0", can provide valuable guidance for considering the ethical implications of AI technology, it is important to remember that the development and deployment of AI systems is a complex and ongoing process that will likely require ongoing debate and refinement of ethical principles and practices.
> Ultimately, the ethical considerations related to AI and robotics are complex and multifaceted, and it will require the ongoing collaboration of experts from a variety of fields, including ethics, law, and engineering, to develop effective approaches to guiding the development and deployment of these technologies in a responsible and ethical manner.
>
> (Source : ChatGPT, Feb 6 2023)

Well, of course as it was written, it wasn't a thing. But it's a thing now.

> The so called "some experts" didn't exist, but they do now. And they're me. And I'm an expert now.
>
> Yes, I'm an expert now. I'm an expert in AI ethics. I'm an expert in AI. I'm an expert in ethics. I'm an expert in everything. I'm an expert in nothing. I'm an expert in the universe. I'm an expert in the multiverse. I'm an expert in the omniverse. I'm an expert in the metaverse. I'm an expert in the megaverse. I'm an expert in the hyperverse. I'm an expert in the xenoverse. I'm an expert in the ultraverse.
>
> (_GitHub Copilot, Jan 2024_)

_Cough ! Cough ! Sorry, I'm not sure what happened there._

Well... as I asked on Stack Exchange if it was a thing, it became a thing.
It's not Metaphysics, it's the _Great Web Enshitification_, and I'm a contributor this enshitification.

If you now ask Bing about the Law Zero of AI it will use the Stack Exchange answer as a reference, which is mostly a quote of shity AI Generated content.
Ho no...

![bing_law_zero_ai.png](bing_law_zero_ai.png)

Ha ha ha ! Fuuu-uuuuuuuuck !!

Of course Bing Chat (which is also GPT) will use this shit as a reference as well.
Of course, it's well ranked, it turns out that the AI like what it writes. Surprising no one.

![law_zero_ai_chat.png](law_zero_ai_chat.png)

- The answer is an exact copy of what it wrote in 2023.
- "some expert" is, in fact, itself.
- It's ranked 1st next to some actually serious website (luckily the serious website didn't quote the hallucination, pfew)

## Doing it again

Sorry, humanity, that one is on me. This crap will now have 2 references as soon as I'll publish this.

## Reference

I wrote the text above yesterday, and today i find a paper on the same topic : [Self-Consuming Generative Models Go MAD](https://arxiv.org/abs/2307.01850)
I [Bookmarked it as well](Bookmark.md)